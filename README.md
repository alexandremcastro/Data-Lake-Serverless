# Data Lake Serverless (AWS)
[![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/alexandremcastro/Data-Lake-Serverless-AWS/blob/main/LICENSE)

> **üìùNota:**: Eu n√£o sou respons√°vel pelos custos do projeto, isso significa que qualquer gasto que ocorra durante a realiza√ß√£o do projeto, como utiliza√ß√£o de servi√ßos, n√£o √© de minha responsabilidade. √â importante que voc√™ esteja ciente desses custos e os gerencie adequadamente.

### Arquitetura do projeto

Este projeto tem como objetivo oferecer um Data Lake na nuvem, sem servidor, utilizando os servi√ßos da Amazon Web Services (AWS).

Para atender a essa necessidade, ofere√ßo a cria√ß√£o de um Data Lake na nuvem, utilizando os servi√ßos da AWS. A AWS √© uma plataforma l√≠der de computa√ß√£o em nuvem que oferece uma ampla variedade de servi√ßos para atender √†s necessidades de diferentes tipos de empresas.

A escolha de uma arquitetura Serverless √© uma op√ß√£o que tem se mostrado cada vez mais popular no mundo da computa√ß√£o em nuvem. Com essa abordagem, a responsabilidade pela infraestrutura √© transferida para o provedor de servi√ßos em nuvem, permitindo que as empresas se concentrem em suas atividades principais.

Al√©m disso, a utiliza√ß√£o de servi√ßos da AWS permite que o Data Lake seja altamente escal√°vel e resiliente, garantindo que ele possa lidar com grandes volumes de dados e oferecer alta disponibilidade aos usu√°rios.

Essa ser√° a arquitetura a ser seguida no projeto:

![Diagrama sem nome.jpg](/Imagens/Diagrama_sem_nome.jpg)

## Tecnologias
[Cloud9](https://aws.amazon.com/pt/cloud9/) ‚Ä¢ [Kinesis](https://aws.amazon.com/pt/kinesis/) ‚Ä¢ [DynamoDB](https://aws.amazon.com/pt/dynamodb/) ‚Ä¢ [IAM](https://aws.amazon.com/pt/iam/) ‚Ä¢ [Lambda](https://aws.amazon.com/pt/lambda/) ‚Ä¢ [S3](https://aws.amazon.com/pt/s3/) ‚Ä¢ [Glue](https://aws.amazon.com/pt/glue/) ‚Ä¢ [Athena](https://aws.amazon.com/pt/athena/)

## Motiva√ß√£o
Este projeto experimental √© o resultado das minhas experi√™ncias com a implementa√ß√£o de um Data Lake Serverless utilizando os servi√ßos da Amazon Web Services (AWS).

Foi uma oportunidade para aplicar meus conhecimentos em tecnologia da AWS e construir uma solu√ß√£o de Data Lake Serverless, que pode ser utilizada por empresas que precisam lidar com grandes volumes de dados. Aprendi muito durante o processo e espero poder utilizar esse conhecimento em projetos futuros.

## Sum√°rio
+ [Pipeline com dados n√£o estruturados](/Documentos/PipelineNaoEstruturado.md#PipelineNaoEstruturado)
    + [Criando o servi√ßo Kinesis Data Streams](/Documentos/PipelineNaoEstruturado.md#CriacaoDataStreams)
    + [Criando uma tabela no DynamoDB](/Documentos/PipelineNaoEstruturado.md#CriacaoDynamoDB)
    + [Administrando pol√≠ticas de seguran√ßa com o IAM](/Documentos/PipelineNaoEstruturado.md#IAM)
    + [Criando uma fun√ß√£o com o servi√ßo Lambda](/Documentos/PipelineNaoEstruturado.md#FuncaoLambda)
    + [Processando dados n√£o estruturados (Data Streams, DynamoDB e Lambda)](/Documentos/PipelineNaoEstruturado.md#ProcessandoNaoEstruturado)
+ [Pipeline com dados estruturados](/Documentos/PipelineEstruturado.md#PipelineEstruturados)
    + [Criando um bucket S3](/Documentos/PipelineEstruturado.md#S3)
    + [Criando uma tabela no Glue](/Documentos/PipelineEstruturado.md#Glue)
    + [Criando o servi√ßo Kinesis Data Firehose](/Documentos/PipelineEstruturado.md#Firehose)
    + [Processando dados estruturados (S3, Glue e Data Firehose)](/Documentos/PipelineEstruturado.md#ProcessandoEstruturados)
    + [Criando e fazendo consultas com o Athena](/Documentos/PipelineEstruturado.md#Athena)

## Requisitos para o projeto
> **üìùNota:**: Este projeto foi conclu√≠do em Fevereiro de 2023, e √© importante ressaltar que alguns dos requisitos abordados podem sofrer altera√ß√µes ao longo do tempo. Como em qualquer √°rea de tecnologia, novas solu√ß√µes e tecnologias surgem constantemente, o que pode tornar algumas das abordagens e solu√ß√µes apresentadas neste projeto desatualizadas em algum momento.


<br/>

**1. Servi√ßo Cloud9**

Para que √© usado o servi√ßo Cloud9? Ele fornece um terminal de comando para uma inst√¢ncia EC2. Isso √© essencial neste projeto, pois ser√° nele que ser√£o gerados os dados para consumo

V√° no painel e na pesquisa procure e clique no servi√ßo Cloud9

![Untitled](/Imagens/Untitled.png)

Voc√™ ser√° redirecionado a essa tela

Clique em: `Criar ambiente`

![Untitled](/Imagens/Untitled%201.png)

Coloque um nome para identifica√ß√£o, a descri√ß√£o √© opcional

Mantenha as outras op√ß√µes em padr√£o

![Untitled](/Imagens/Untitled%202.png)

> **üí°**: Verifique se a inst√¢ncia que est√° sendo criada √© coberta pelo n√≠vel gratuito.

<br>

![Untitled](/Imagens/Untitled%203.png)

Para criar a o Cloud9, clique em `Criar`

![Untitled](/Imagens/Untitled%204.png)

Para acessar o terminal criado pelo Cloud9, clique em: `Em aberto`

![Untitled](/Imagens/Untitled%205.png)

A cria√ß√£o do servi√ßo demora alguns minutos, pois ainda ser√° criado o servi√ßo EC2 simultaneamente. Ao criar voc√™ ser√° redirecionado para essa tela:

![Untitled](/Imagens/Untitled%206.png)

√â importante manter essa tela aberta at√© o fim do projeto, nela que ser√° rodado o script respons√°vel por gerar os dados para o Data Lake

<br>

**2. Arquivos do Producer e Consumer**

Baixando o Producer e Consumer

Para baixar o Producer/Consumer, abra a janela com o terminal do Cloud9 e rode o comando:

```bash
curl -s [https://data-processing.serverlessworkshops.io/client/client.tar](https://data-processing.serverlessworkshops.io/client/client.tar) | tar -xv
```

![Untitled](/Imagens/Untitled%207.png)

Essa etapa ser√° repetida algumas vezes, ent√£o √© de extrema import√¢ncia saber como realizar ela at√© o fim do projeto

<br>

<b> Producer </b>

O Producer √© respons√°vel por simular os dados dos sensores nos cavalos, √© um script fornecido pela AWS feito em Go, j√° compilado.

Para come√ßar gerar os dados, abra o terminal do Cloud9 e rode o comando:

```bash
./producer
```

![Untitled](/Imagens/Untitled%208.png)

<br>

<b> Consumer </b>

O Consumer √© respons√°vel por consumir os dados dos sensores nos cavalos, neste caso, o Consumer est√° lendo os dados gerados pelo Producer, o Consumer tamb√©m √© um script fornecido pela AWS feito em Go, j√° compilado.

Para verificar se est√° tudo funcionando corretamente, abra uma nova janela do terminal e rode o comando:

```bash
./consumer
```

![Untitled](/Imagens/Untitled%209.png)

Para parar de rodar ambos, fa√ßa o comando: `CTRL + C`

## Tarefas

**Tarefas conclu√≠das**
- [x] Descrever sobre a finalidade do Data Lake
- [x] Realizar os requisitos m√≠nimos
- [x] Configurar os servi√ßos AWS
- [x] Testar/Verificar o Data Lake

**Futuras implementa√ß√µes**
- [ ] Simular novas requisi√ß√µes do cliente
- [ ] Acrescentar novos servi√ßos ao Data Lake, atentendo ao cliente
- [ ] Montar um relat√≥rio de consumo mensal com o servi√ßo Billing
- [ ] Organizar os dados em camadas, semelhante a medalh√£o

## Links
**Projeto:**

[Projeto no Site](https://alexandre-castro.vercel.app/blog/datalake-serverless)

[Projeto no Notion](https://alexandremcastro.notion.site/02-2023-AWS-Data-Lake-Serverless-c8f8198221134364991976c26ee1a985)

[Projeto no GitLab](https://gitlab.com/alexandremcastro/Data-Lake-Serverless-AWS)

[Projeto no GitHub](https://github.com/alexandremcastro/Data-Lake-Serverless-AWS)

**Artigos orientadores:**

[Computa√ß√£o sem servidor - AWS](https://aws.amazon.com/pt/serverless/)

[Conceitos b√°sicos da arquitetura sem servidor da AWS - AWS](https://aws.amazon.com/pt/serverless/getting-started/?serverless.sort-by=item.additionalFields.createdDate&serverless.sort-order=desc)

[Deploying Code Faster with Serverless Framework and AWS Service Catalog - AWS](https://aws.amazon.com/pt/blogs/apn/deploying-code-faster-with-serverless-framework-and-aws-service-catalog/)

[Deploy and manage a serverless data lake on the AWS Cloud by using infrastructure as code - AWS](https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/deploy-and-manage-a-serverless-data-lake-on-the-aws-cloud-by-using-infrastructure-as-code.html)

## Conclus√£o 
Em resumo, a proposta desse projeto √© criar um Data Lake em nuvem, Serverless, utilizando os servi√ßos da AWS, permitindo que as empresas possam armazenar, processar e analisar grandes volumes de dados de maneira escal√°vel e eficiente.
