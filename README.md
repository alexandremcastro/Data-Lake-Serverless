# 02/2023 - (AWS) Data Lake Serverless

## Introdu√ß√£o

- Arquitetura do projeto
    
    ## Objetivo
    
    A proposta desse projeto √© fornecer um Data Lake em nuvem, Serverless, utilizando os servi√ßos da Amazon Web Services.
    
    ![Diagrama sem nome.jpg](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Diagrama_sem_nome.jpg)
    

---

- Criando o servi√ßo Cloud9
    
    Para que √© usado o servi√ßo Cloud9? Ele fornece um terminal de comando para uma inst√¢ncia EC2. Isso √© essencial neste projeto, pois ser√° nele que ser√£o gerados os dados para consumo
    
    V√° no painel e na pesquisa procure e clique no servi√ßo Cloud9
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled.png)
    
    Voc√™ ser√° redirecionado a essa tela
    
    Clique em: `Criar ambiente`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%201.png)
    
    Coloque um nome para identifica√ß√£o, a descri√ß√£o √© opcional
    
    Mantenha as outras op√ß√µes em padr√£o
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%202.png)
    
    <aside>
    üí° Verifique se a inst√¢ncia que est√° sendo criada √© coberta pelo n√≠vel gratuito.
    
    </aside>
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%203.png)
    
    Para criar a o Cloud9, clique em `Criar`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%204.png)
    
    Para acessar o terminal criado pelo Cloud9, clique em: `Em aberto`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%205.png)
    
    A cria√ß√£o do servi√ßo demora alguns minutos, pois ainda ser√° criado o servi√ßo EC2 simultaneamente. Ao criar voc√™ ser√° redirecionado para essa tela:
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%206.png)
    
    √â importante manter essa tela aberta at√© o fim do projeto, nela que ser√° rodado o script respons√°vel por gerar os dados para o Data Lake
    

---

- Rodando o Producer e Consumer
    
    ### Baixando o Producer e Consumer
    
    Para baixar o Producer/Consumer, abra a janela com o terminal do Cloud9 e rode o comando:
    
    ```bash
     curl -s [https://data-processing.serverlessworkshops.io/client/client.tar](https://data-processing.serverlessworkshops.io/client/client.tar) | tar -xv
    ```
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%207.png)
    
    Essa etapa ser√° repetida algumas vezes, ent√£o √© de extrema import√¢ncia saber como realizar ela at√© o fim do projeto
    
    ### Producer
    
    O Producer √© respons√°vel por simular os dados dos sensores nos cavalos, √© um script fornecido pela AWS feito em Go, j√° compilado.
    
    Para come√ßar gerar os dados, abra o terminal do Cloud9 e rode o comando:
    
    ```bash
    ./producer
    ```
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%208.png)
    
    ### Consumer
    
    O Consumer √© respons√°vel por consumir os dados dos sensores nos cavalos, neste caso, o Consumer est√° lendo os dados gerados pelo Producer, o Consumer tamb√©m √© um script fornecido pela AWS feito em Go, j√° compilado.
    
    Para verificar se est√° tudo funcionando corretamente, abra uma nova janela do terminal e rode o comando:
    
    ```bash
    ./consumer
    ```
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%209.png)
    
    Para parar de rodar ambos, fa√ßa o comando: `CTRL + C`
    

---

## Pipeline com dados n√£o estruturados

- Criando o servi√ßo Kinesis Data Streams
    
    Para que √© usado o servi√ßo Kinesis? O AWS Kinesis √© um servi√ßo de streaming de dados, usado para coletar, processar e analisar grandes volumes de dados em tempo real.
    
    O Kinesis Data Streams ser√° necess√°rio no projeto para capturar os dados gerados pelo Producer.
    
    V√° no painel e na barra pesquisa procure por `Kinesis`
    
    Clique em: `Kinesis`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2010.png)
    
    Nesta tela, selecione: `Kinesis Data Streams` 
    
    Em seguida, selecione: `Criar fluxo de dados`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2011.png)
    
    Insira o nome do fluxo de dados como: `wildrydes`
    
    Selecione a capacidade do fluxo de dados para: `Provisionado`
    
    Mantenha as outras op√ß√µes em padr√£o
    
    Em seguida clique em: `Criar fluxo de dados`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2012.png)
    

---

- Criando uma tabela no DynamoDB
    
    Para que √© usado o servi√ßo DynamoDB? O AWS DynamoDB √© um servi√ßo de banco de dados NoSQL, que permite armazenar e recuperar grandes volumes de dados de forma r√°pida e escal√°vel, sem a necessidade de provisionar ou gerenciar servidores. Ele ser√° uma das fontes de armazenamentos de dados do Data Lake.
    
    V√° no painel e na barra pesquisa procure por `DynamoDB`
    
    Clique em: `DynamoDB`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2013.png)
    
    Para criar a tabela que receberemos os dados, clique em: `Criar tabela`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2014.png)
    
    Como nome da tabela utilize o nome: `UnicornSensorData`
    
    Como chave de parti√ß√£o utilize: `Name`
    
    Como chave de classifica√ß√£o utilize: `StatusTime`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2015.png)
    
    As pr√≥ximas op√ß√µes s√£o padr√£o
    
    Ao fim da p√°gina, clique em: `Criar tabela`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2016.png)
    

---

- Administrando pol√≠ticas de seguran√ßa com o IAM
    
    Para que √© usado o servi√ßo IAM? O AWS IAM (Identity and Access Management) √© um servi√ßo de gerenciamento de identidade e acesso, usado para gerenciar o acesso a recursos da AWS de forma segura, permitindo gerenciar usu√°rios, grupos e permiss√µes de acesso aos servi√ßos.
    
    V√° no painel e na barra pesquisa procure por `IAM`
    
    Clique em: `IAM`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2017.png)
    
    - Cria√ß√£o da pol√≠tica
        
        Criarei uma politica para o DynamoDB permitir a grava√ß√£o de dados na tabela criada.
        
        Na p√°gina redirecionada, clique em: `Politicas`
        
        ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2018.png)
        
        Em seguida clique em: `Criar politica`
        
        ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2019.png)
        
        No servi√ßo, selecione: `DynamoDB`
        
        Nas a√ß√µes, selecione: `BatchWriteItem`
        
        ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2020.png)
        
        Em recursos, selecione: `Adicionar ARN`
        
        ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2021.png)
        
        Para preencher essa tabela, √© necess√°rio do c√≥digo ARN da tabela criada no DynamoDB
        
        ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2022.png)
        
        Para ter acesso ao ARN da tabela no DynamoDB, v√° no servi√ßo e clique na tabela que foi criada
        
        ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2023.png)
        
        O ARN fica localizado nas informa√ß√µes gerais da tabela
        
        Copie o c√≥digo ARN
        
        ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2024.png)
        
        Cole o c√≥digo ARN e todas as informa√ß√µes ser√£o preenchidas automaticamente
        
        Clique em: `Adicionar`
        
        ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2025.png)
        
        Prosseguindo a cria√ß√£o da pol√≠tica
        
        Clique em: `Pr√≥ximo: Tags`
        
        ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2026.png)
        
        Clique em: `Pr√≥ximo: Revisar`
        
        ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2027.png)
        
        Em nome, insira: `WildRydesDynamoDBWritePolicy`
        
        Ap√≥s, clique em: `Criar pol√≠tica`
        
        ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2028.png)
        
    - Cria√ß√£o da fun√ß√£o
        
        Agora irei criar uma fun√ß√£o para o Lambda se comunicar com o Kinesis e DynamoDB utilizando as politicas:`WildRydesDynamoDBWritePolicy` e `AWSLambdaKinesisExecutionRole`
        
        Clique em: `Fun√ß√µes`
        
        Depois clique em: `Criar fun√ß√£o`
        
        ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2029.png)
        
        Em caso de uso, selecione `Lambda`
        
        Depois clique em: `Pr√≥ximo`
        
        ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2030.png)
        
        Pesquise pela pol√≠tica `AWSLambdaKinesisExecutionRole`
        
        Selecione a pol√≠tica: `AWSLambdaKinesisExecutionRole`
        
        ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2031.png)
        
        Pesquise pela pol√≠tica `WildRydesDynamoDBWritePolicy`
        
        Selecione a pol√≠tica: `WildRydesDynamoDBWritePolicy`
        
        ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2032.png)
        
        Confirme se as duas pol√≠ticas est√£o selecionadas
        
        ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2033.png)
        
        Prossiga a cria√ß√£o da fun√ß√£o
        
        Selecione: `Pr√≥ximo`
        
        ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2034.png)
        
        Em nome da fun√ß√£o, insira: `WildRydesStreamProcessorRole`
        
        ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2035.png)
        
        Verifique as pol√≠ticas selecionadas
        
        Selecione: `Criar fun√ß√£o`
        
        ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2036.png)
        
        Verifique se a fun√ß√£o foi criada
        
        ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2037.png)
        
    

---

- Criando uma fun√ß√£o com o servi√ßo Lambda
    
    Para que √© usado o servi√ßo Lambda? √â um servi√ßo para rodar c√≥digos de diversas linguagens diferentes, nele rodar√° o c√≥digo que ser√° respons√°vel por trazer os dados do Kinesis e levar para o DynamoDB.
    
    V√° no painel e na barra pesquisa procure por `Lambda`
    
    Clique em: `Lambda`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2038.png)
    
    Clique em: `Criar uma fun√ß√£o`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2039.png)
    
    Em nome da fun√ß√£o, insira o nome: `WildRydesStreamProcessor`
    
    Selecione abaixo a op√ß√£o de execu√ß√£o: `Node.js 14.x`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2040.png)
    
    No papel de execu√ß√£o, selecione a op√ß√£o: `Usar uma fun√ß√£o existente`
    
    Na fun√ß√£o, selecione a `WildRydesStreamProcessorRole`, criada anteriormente na se√ß√£o do IAM
    
    Em seguida, selecione: `Criar fun√ß√£o`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2041.png)
    
    Na parte de c√≥digo, insira o c√≥digo a seguir:
    
    ```jsx
    "use strict";
    
    const AWS = require("aws-sdk");
    const dynamoDB = new AWS.DynamoDB.DocumentClient();
    const tableName = process.env.TABLE_NAME;
    
    exports.handler = function (event, context, callback) {
        const requestItems = buildRequestItems(event.Records);
        const requests = buildRequests(requestItems);
    
        Promise.all(requests)
            .then(() =>
                callback(null, `Delivered ${event.Records.length} records`)
            )
            .catch(callback);
    };
    
    function buildRequestItems(records) {
        return records.map((record) => {
            const json = Buffer.from(record.kinesis.data, "base64").toString(
                "ascii"
            );
            const item = JSON.parse(json);
    
            return {
                PutRequest: {
                    Item: item,
                },
            };
        });
    }
    
    function buildRequests(requestItems) {
        const requests = [];
        // Batch Write 25 request items from the beginning of the list at a time
        while (requestItems.length > 0) {
            const request = batchWrite(requestItems.splice(0, 25));
    
            requests.push(request);
        }
    
        return requests;
    }
    
    function batchWrite(requestItems, attempt = 0) {
        const params = {
            RequestItems: {
                [tableName]: requestItems,
            },
        };
    
        let delay = 0;
    
        if (attempt > 0) {
            delay = 50 * Math.pow(2, attempt);
        }
    
        return new Promise(function (resolve, reject) {
            setTimeout(function () {
                dynamoDB
                    .batchWrite(params)
                    .promise()
                    .then(function (data) {
                        if (data.UnprocessedItems.hasOwnProperty(tableName)) {
                            return batchWrite(
                                data.UnprocessedItems[tableName],
                                attempt + 1
                            );
                        }
                    })
                    .then(resolve)
                    .catch(reject);
            }, delay);
        });
    }
    ```
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2042.png)
    
    Antes do Deploy, v√° nas configura√ß√µes de vari√°veis de ambiente
    
    Clique em: `Editar`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2043.png)
    
    **Primeira vari√°vel de ambiente**
    
    Clique em: `Adicionar vari√°veis de ambiente`
    
    Na primeira vari√°vel de ambiente, insira:
    
    Chave: `TABLE_NAME`
    
    Valor: `UnicornSensorData`
    
    **Segunda vari√°vel de ambiente**
    
    Clique em: `Adicionar vari√°veis de ambiente`
    
    Na segunda vari√°vel de ambiente, insira:
    
    Chave: `AWS_NODEJS_CONNECTION_REUSE_ENABLED`
    
    Valor: `1`
    
    Clique em: `Salvar`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2044.png)
    
    Adicionando o Kinesis na fun√ß√£o
    
    Clique em: `Adicionar gatilho`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2045.png)
    
    Selecione o servi√ßo: `Kinesis` 
    
    Em Stream do Kinesis, insira o stream criado anteriormente no Kinesis Data Streams
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2046.png)
    
    Mantenha o tamanho do lote em 100
    
    Clique em: `Adicionar`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2047.png)
    
    Com tudo configurado, farei o Deploy da fun√ß√£o
    
    V√° na aba C√≥digo e clique em: `Deploy`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2048.png)
    

---

- Processando dados n√£o estruturados **(Data Streams, DynamoDB e Lambda)**
    
    Com o Kinesis, DynamoDB, IAM e Lambda criados e configurados, agora √© poss√≠vel fazer o processamento dos dados gerados pelo script Producer.
    
    Com o Cloud9 aberto, rode o Producer, mencionando o stream criado no Kinesis
    
    ```bash
    ./producer -stream wildrydes
    ```
    
    Rode o Consumer e verifique a produ√ß√£o dos dados
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2049.png)
    
    Na aba `Monitor`, verifique se os dados est√£o sendo capturados
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2050.png)
    
    Para verificar se os dados est√£o sendo entregues, abra o servi√ßo `DynamoDB`
    
    V√° na aba tabelas e selecione a tabela `UnicornSensorData`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2051.png)
    
    Clique em: `Explorar itens da tabela`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2052.png)
    
    Verifique se os dados foram preenchidos
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2053.png)
    

## Pipeline com dados estruturados

- Criando um bucket S3
    
    Para que √© usado o servi√ßo S3? O S3 √© um sistema de armazenamento, nele pode ser armazenado qualquer tipo de arquivo
    
    Depois de ter enviado os dados para o DynamoDB, temos a op√ß√£o de enviar eles para o S3
    
    V√° no painel e na barra pesquisa procure por `S3`
    
    Clique em: `S3`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2054.png)
    
    Clique em: `Criar bucket`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2055.png)
    
    <aside>
    üí° Ao nomear o bucket, de um nome inexistente at√© o momento, o nome do bucket deve ser globalmente exclusivo.
    
    </aside>
    
    Insira o nome do bucket
    
    Em Regi√£o da AWS, selecione: `Leste dos EUA¬†(Norte da Virg√≠nia) us-east-1`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2056.png)
    
    Mantenha as outras configura√ß√µes padr√µes
    
    Clique em: `Criar bucket`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2057.png)
    

---

- Criando uma tabela no Glue
    
    Para que √© usado o servi√ßo Glue? O Glue √© um servi√ßo de integra√ß√£o de dados, nele ser√° poss√≠vel capturar os dados vindo do Kinesis e levando ele ao bucket S3.
    
    V√° no painel e na barra pesquisa procure por `Glue`
    
    Clique em: `AWS Glue`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2058.png)
    
    V√° na aba `Tables`, em Data Catalog
    
    Clique em: `Add table`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2059.png)
    
    Em Table details, insira um nome para a tabela
    
    Em Database, selecione: `default`
    
    <aside>
    üí° Caso n√£o apare√ßa nenhum banco de dados, crie um no bot√£o: `Create database`
    
    </aside>
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2060.png)
    
    Em Data Store, selecione a op√ß√£o: `S3`
    
    Depois selecione onde est√° localizado o bucket, clique em: `Browse S3`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2061.png)
    
    Selecione o bucket criado anteriormente
    
    Clique em: `Choose`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2062.png)
    
    Em Data format, selecione o formato: `Parquet`
    
    Clique em: `Next`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2063.png)
    
    Para definir o schema, clique em: `Add`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2064.png)
    
    O schema deve ser baseado nas informa√ß√µes geradas pelo Producer
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2065.png)
    
    Insira cada coluna do schema, seguindo a ordem de sa√≠da gerada pelo Producer e seguindo os tipos de dados.
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2066.png)
    
    Repita esse processo para todas as colunas
    
    | Coluna | Tipo |
    | --- | --- |
    | Distance | float |
    | HealthPoints | int |
    | Latitude | float |
    | Longitude | float |
    | MagicPoints | int |
    | Name | string |
    | InputData | string |
    | StatusTime | timestamp |
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2067.png)
    
    Mantenha as outras configura√ß√µes em padr√£o
    
    Clique em: `Next`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2068.png)
    
    Verifique se tudo est√° corretamente configurado
    
    Clique em: `Create`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2069.png)
    

---

- Criando o servi√ßo Kinesis Data Firehose
    
    V√° no painel e na barra pesquisa procure por `Kinesis`
    
    Clique em: `Kinesis`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2010.png)
    
    Clique em: `Criar stream de entrega`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2070.png)
    
    Na origem, selecione: `Amazon Kinesis Data Streams`
    
    No destino, selecione: `Amazon S3`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2071.png)
    
    Na configura√ß√£o da origem, clique em: `Browse`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2072.png)
    
    Selecione o Data stream criado anteriormente
    
    Clique em: `Choose`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2073.png)
    
    Insira um nome para o fluxo de entrega
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2074.png)
    
    Em transformar e converter registros, selecione: `Ativar convers√£o de formato de registro`
    
    Em formato de sa√≠da, selecione: `Apache Parquet`
    
    Em regi√£o, selecione `Leste dos EUA (Norte da Virg√≠nia)`
    
    Em banco de dados do AWS Glue, selecione o banco de dados criado no Glue
    
    Em tabela do AWS Glue, selecione a tabela criada no Glue
    
    ![Captura da Web_14-3-2023_185721_us-east-1.console.aws.amazon.com.jpeg](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Captura_da_Web_14-3-2023_185721_us-east-1.console.aws.amazon.com.jpeg)
    
    Em configura√ß√µes do destino, clique em: `Browse`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2075.png)
    
    Selecione o bucket criado anteriormente
    
    Clique em: `Choose`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2076.png)
    
    Em intervalo do buffer, coloque `60`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2077.png)
    
    Clique em: `Criar fluxo de entrega`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2078.png)
    

---

- Processando dados estruturados **(S3, Glue e Data Firehose)**
    
    Com tudo configurado, agora √© os dados gerados pelo Producer, ser√£o enviados diretamente para o S3.
    
    Para isso, rode o Producer indicando o nome do Stream
    
    ```bash
    ./producer -stream wildrydes
    ```
    
    Deixe alguns minutos rodando
    
    Acesse o bucket criado e cheque se foi criado um diret√≥rio
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2079.png)
    
    Siga at√© o √∫ltimo destino e verifique se l√° possuem os objetos `.parquet`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2080.png)
    
    Clique em qualquer objeto
    
    Dentro do objeto, clique em: `Consulta com o S3 Select`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2081.png)
    
    Em configura√ß√µes de entrada, selecione o formato: `Apache Parquet`
    
    Em configura√ß√µes de sa√≠da, selecione o formato: `CSV`
    
    ![Captura da Web_14-3-2023_192012_us-east-1.console.aws.amazon.com.jpeg](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Captura_da_Web_14-3-2023_192012_us-east-1.console.aws.amazon.com.jpeg)
    
    Em consulta SQL, selecione: `Executar consulta SQL`
    
    Em resultados da consulta, verifique se o resultado da consulta, batem com os mesmos dados gerados pelo Producer.
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2082.png)
    

---

- Criando e fazendo consultas com o Athena
    
    Para que √© usado o servi√ßo Athena? Com o Athena √© poss√≠vel analisar dados, utilizando consultas em SQL, √© poss√≠vel utilizar como fonte de dados o S3 e outros servi√ßos
    
    V√° no painel e na pesquisa procure e clique no servi√ßo Athena
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2083.png)
    
    Selecione: `Query your data`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2084.png)
    
    Verifique se o database selecionado √© o que foi criado anteriormente
    
    Verifique se a tabela selecionada √© a que foi criada anteriormente
    
    Fa√ßa uma consulta simples, verificando se est√° tudo funcionando corretamente
    
    ```sql
    SELECT * FROM wildrydes_table
    ```
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2085.png)
    
    Clique em: `Run`
    
    ![Untitled](02%202023%20-%20(AWS)%20Data%20Lake%20Serverless%20c8f8198221134364991976c26ee1a985/Untitled%2086.png)